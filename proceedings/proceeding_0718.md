- 첫 회의를 진행
- 각자 지금 하고 있는 부분 이야기, 전체 프로젝트 기획 재설명
    - LLM Part
        - 우선 간단하게 Prototype을 구성할 예정
            - Prototype : 단백질 서열을 1200dim vector로 embedding하여 input으로 제공할 때, 이를 기반으로 Output을 출력하는 Decoder 계열의 Language Model 제작
        - 이후에 아래와 같은 다양한 방식에 대해 고민, 시도해볼 예정
            - Reinforcement Learning 적용
            - CoT 구조의 추론 방식으로 학습
            - User Query와 함께 input (Soft Prompt)
        

- 다음 해야할 일 정의
- 길원
    - [X] Find parameter efficient open source model
        - Rostlab/prot_bert ( < 3B)
        - [A Fine-tuning Dataset and Benchmark for Large Language Models for Protein Understanding](https://arxiv.org/pdf/2406.05540)
            - Normal LLM
                - internlm/internlm-7b/20b
                - Mistral-7B-instruct-v0.2
                - SmolLM3 3B
                - EXAONE 4.0 1.2B	
                - Llama 3.1 Nemotron Nano 8B V1	
                - Llama 3.2 3B Instruct
                - Gemma 3 4B
            --- 
            - Bio LLM
                - BioMistral/BioMistral-7B
    - [X] Find evaluation metric 
        - ProteinLMBench (RAG+GPT로 생성한 944sample Dataset)
        - PEER

- LLM 개발 팀
    - [ ] Reinforcement Learning 학습
        - [Survey Paper](https://arxiv.org/pdf/2412.10400)
    - [ ] 현규님이 공유해주신 Paper 학습
        - [ProtT3](https://aclanthology.org/2024.acl-long.324.pdf)
    - [ ] LoRA 실습 베이스라인 코드를 기반으로 성능 향상 개별적 연구
    - [ ] Soft Prompt 실습 베이스라인 코드를 기반으로 성능 향상 개별적 연구
